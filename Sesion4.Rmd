---
title: "Taller R:Sesion 4"
author: "Maria Jose Zambrano"
date: "2023-10-19"
output: html_document
---

En nuestra ultima sesion del taller vamos a ver un poco de reduccion de dimensionalidad, clustering, como procesar texto, veremos un breve ejemplo de como hacer una aplicacion web con R y terminameros con una breve introduccion a git (no es R, pero es muy util). 

## Reduccion de dimensionalidad

A veces nuestros datos tienen muchas dimensiones, lo que puede ser un poco incomodo y afectar los procesos que hacemos (maldision de la dimensionalidad), por eso hay tecnicas para reducir las dimensiones de los datos. Podemos eliminar columnas que tengan muchos nulos, algunas que no aporten mucha informacion o algunas columnas que estén muy relacionadas entre si. Tambien hay algoritmos, como PCA y TSNE que se encargan de capturar la parte mas importante de los datos, aquí veremos ejemplos de ambos con un dataset de vinos:

```{r}
df <- read.csv("https://raw.githubusercontent.com/mzambrano1/Taller-R-2023/main/Datasets/wine-clustering.csv")
head(df)
```

Ejecutamos PCA:

```{r}
pca <- prcomp(df, scale = TRUE)
pca
head(pca$x)
```


Y Ahora podemos graficar los datos con dos diminesiones:

```{r}
plot(pca$x[,1],pca$x[,2])
```

Ahora veamos con tsne:

```{r,eval=FALSE}
install.packages("tsne")
```


Le decimos que queremos 2 dimensiones:

```{r}
library(tsne)

tsne <- tsne(df, k = 2, perplexity = 30, epoch = 100)
head(tsne)
```


Y podemos graficar de nuevo:

```{r}
plot(tsne[,1],tsne[,2])
```


## Clustering

La sesion pasada vimos como hacer uso de algunos algoritmos de clasificacion en R, a esto se le llama aprendizaje supervisado, ya que se entrena un modelo para que aprenda a partir de datos etiquetados. El clustering es un tipo de aprendizaje no supervisado, porque no necesitamos que los datos esten etiquetados, los algoritmos se encarga de agrupar los datos que se aprecen entre si. Para esto hay distintos algoritmos, aqui veremos ejemplos con 2: K-means y dbscan.


```{r,eval=FALSE}
install.packages("ggpubr")
```


K-means agrupa los datos en K clusters. Para este algorimo es necesario darle el numero de clusters que se requieren, luego genera k centroides aleatorios en los datos y los va ajustando para que queden los mas centrales a los cluesters posible.

Para determinar el numero de clusters que mejor se ajusta a los datos existe el metodo del codo, en el cual se calcula la distancia media de los datos a se centroide y se va graficando esto, el numero optimo de clusters se tendra cuando se vea un "codo" en la linea:


```{r}
library(ggplot2)

set.seed(1234)
wcss <- vector()
for(i in 1:20){
  wcss[i] <- sum(kmeans(df, i)$withinss)
}


ggplot() + geom_point(aes(x = 1:20, y = wcss), color = 'blue') + 
  geom_line(aes(x = 1:20, y = wcss), color = 'blue') + 
  ggtitle("Método del Codo") + 
  xlab('Cantidad de Centroides k') + 
  ylab('WCSS')
```


Ahora que ya sabemos cuantos clusters necesitamos podemos ejecutar K-means:

```{r}
library(tidyverse)
library(ggpubr)

km_clusters <- kmeans(x = df, centers = 3, nstart = 50)
km_clusters
```

```{r}
km_clusters$cluster
```

Y podemos ver graficamente como quedaron los clusters:

```{r}
ggplot() + geom_point(aes(x = pca$x[,1], y = pca$x[,2], color = km_clusters$cluster)) +
  scale_colour_gradientn(colours=rainbow(4)) +
  xlab('X') + ylab('Y')
```


Ahora veamos dbscan, este algoritmo encuentra cluster basados en densidad, o sea va buscando sectores de alta densidad de datos y los va agrupando, cuando encuentra que la densidad disminuye es que el cluster cambia. Este algoritmo no necesita que le demos el numero de cluster, lo encuentra solito, pero si requiere ajustar el parametro `eps` que nos dice que tan separados tienen que estar los puntos entre si para considerarse un clusters.


```{r, eval=FALSE}
install.packages("fpc")
install.packages("dbscan")
install.packages("factoextra")
```


Para ajustar este parametro existe el metodo de la rodilla, similar al del codo, cuando sea vea una "rodilla" es que se tiene el parametro optimo:


```{r}
library(fpc)
library(dbscan)
library(factoextra)

dbscan::kNNdistplot(df, k = 5)
```

Ahora podemos ejecutar dbscan con nuestro eps encotrado:

```{r}
set.seed(321)


dbscan_cluster <- fpc::dbscan(data = df, eps = 50, MinPts = 5)


head(dbscan_cluster$cluster)
```


Y verlo visualmente:


```{r}
ggplot() + geom_point(aes(x = pca$x[,1], y = pca$x[,2], color = dbscan_cluster$cluster)) +
  scale_colour_gradientn(colours=rainbow(4)) +
  xlab('X') + ylab('Y')
```



## Texto

Vamos a ver un poco de lo basico de como trabajar con texto. Para vamos a usar mensajes de redes sociales. (adapatación de tutorial de mineria de datos)

```{r,eval=FALSE}
install.packages("tm")
```

```{r}
library(tm)
```

```{r}
msj <- read.csv("http://users.dcc.uchile.cl/~hsarmien/mineria/datasets/messages.csv",sep = ";", quote = "\"'")
head(msj)
```
Primero es necesario convertir los mensajes a un formato que pueda leer `tm` y luego creamos un corpus (coleccion de documentos).

```{r}
docs <- VectorSource(msj[, 2])
docs <- VCorpus(docs)
docs
```
```{r, eval=FALSE}
inspect(docs)
```



Para poder trabajar con el texto es necesario realizar ciertos preprocesamientos, como remover puntuaciones, numeros, entre otras cosas para que estas cosas no nos molesten al tabajar:

```{r}
docs <- tm_map(docs, removePunctuation) #remover puntuacion
docs <- tm_map(docs, removeNumbers) #remover numeros
docs <- tm_map(docs, content_transformer(tolower)) #pasar todo a minuscula
docs <- tm_map(docs, stripWhitespace) #sacar los espacios en blanco que son mas que dos
docs <- tm_map(docs, content_transformer(gsub), pattern = "/", replacement = "")
docs <- tm_map(docs, content_transformer(gsub), pattern = '[[:digit:]]+', replacement = "")  #elimina cualquier digito
docs <- tm_map(docs, content_transformer(gsub), pattern = "/", replacement = "")
docs <- tm_map(docs, content_transformer(gsub), pattern = '[[:digit:]]+', replacement = "")  #elimina cualquier digito
removeSpecialChars <- function(x) gsub("[^ñÑa-zA-Z0-9 ]","",x) #remover mas caracteres especiales que no estaban en removePunctuation
docs <- tm_map(docs, content_transformer(removeSpecialChars))

```

Ahora Podemos hacer una matriz documento-termino. Esta para cada documento nos dice la cantidad de veces que aparece cada palabra.

```{r}
dtm <- DocumentTermMatrix(docs)
inspect(dtm)
```
```{r}
dim(dtm)
```
Ahora podemos extraer los terminos mas frecuentes y ponerlos en un grafiquito:

```{r}
library(ggplot2)
dtm.matrix <- as.matrix(dtm) 
freq <- colSums(dtm.matrix)
word_freq <- data.frame(word = names(freq), freq = freq, row.names = NULL)
word_freq <- word_freq[order(-word_freq$freq),]
ggplot(word_freq[1:20,], aes(x = reorder(word, freq), y = freq)) +
          geom_bar(stat = "identity") + 
          coord_flip()+
          ggtitle(label = "Top-20 palabras de la colección")
```

```{r}
head(stopwords("spanish"),20)
```
Squemos los stopwords:

```{r}
docs <- tm_map(docs, removeWords, stopwords("spanish"))
stopwords_es <- read.table("https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/stopwords_es.txt" , stringsAsFactors = F)
stopwords_es$V1 <- iconv(stopwords_es$V1, from="latin1",to="ASCII//TRANSLIT")
docs <- tm_map(docs, removeWords, stopwords_es$V1)
```

Veamos de nuevo las palabras mas frecuentes:

```{r}
dtm.sw <- DocumentTermMatrix(docs)
dtm.sw.matrix <- as.matrix(dtm.sw)
freq.sw <- colSums(dtm.sw.matrix)
word_freq.sw <- data.frame(word = names(freq.sw), freq = freq.sw, row.names = NULL)
word_freq.sw <- word_freq.sw[order(-word_freq.sw$freq),]

ggplot(word_freq.sw[1:20,], aes(x = reorder(word, freq), y = freq)) +
          geom_bar(stat = "identity") + 
          coord_flip()+
          ggtitle(label = "Top-20 palabras de la colección sin stopwords")
```



## Desarrollo web

La librería Shiny <https://shiny.posit.co/r/getstarted/shiny-basics/lesson1/index.html> nos permite crear aplicaciones web con R.

```{r,eval=FALSE}
install.packages("shiny")
install.packages("shinydashboard")
```

Un ejemplo de la libreria:

```{r,eval=FALSE}
library(shiny)
runExample("01_hello")
```




Ejemplo de <https://www.diegocalvo.es/cuadro-mando-dashboard-shiny-r-app-r/>




```{r,eval=FALSE}
library(shiny)
library(shinydashboard)


ui <- dashboardPage(
  dashboardHeader(
    title = "Shiny"
  ),
  
  dashboardSidebar(
    sidebarMenu(id="sbmenu",
      menuItem("menu1_",tabName = "menu1" ,
        menuSubItem('Sub Menu 1', tabName = 'menu11'),
        menuSubItem('Sub Menu 2', tabName = 'menu12'),
        menuSubItem('Sub Menu 3', tabName = 'menu13')
      ),
      
      menuItem("menu2_",tabName = "menu2" ,
        menuSubItem('Sub Menu 1', tabName = 'menu21'),
        menuSubItem('Sub Menu 2', tabName = 'menu22'),
        menuSubItem('Sub Menu 3', tabName = 'menu23')
      ),
      
      menuItem("menu3_",tabName = "menu3" ,
        menuSubItem('Sub Menu 1', tabName = 'menu31'),
        menuSubItem('Sub Menu 2', tabName = 'menu32'),
        menuSubItem('Sub Menu 3', tabName = 'menu33')
      ),
      
      menuItem("menu4_",tabName = "menu4" ,
        menuSubItem('Sub Menu 1', tabName = 'menu41'),
        menuSubItem('Sub Menu 2', tabName = 'menu42'),
        menuSubItem('Sub Menu 3', tabName = 'menu43')
      ),
      
      menuItem("menu5_",tabName = "menu5" ,
        menuSubItem('Sub Menu 1', tabName = 'menu51'),
        menuSubItem('Sub Menu 2', tabName = 'menu52'),
        menuSubItem('Sub Menu 3', tabName = 'menu53')
      ),
      
      menuItem("menu6_",tabName = "menu6",
        menuSubItem('Sub Menu 1', tabName = 'menu61'),
        menuSubItem('Sub Menu 2', tabName = 'menu62'),
        menuSubItem('Sub Menu 3', tabName = 'menu63')
      )
    )
  ),
  
  dashboardBody(
    tabItems(
      tabItem("menu11",h1("Pagina 1 en construccion")),
      tabItem("menu12",h1("Pagina 2 en construccion")),
      tabItem("menu13",h1("Pagina 3 en construccion")),
      
      tabItem("menu21",h1("Pagina 1 en construccion")),
      tabItem("menu22",h1("Pagina 2 en construccion")),
      tabItem("menu23",h1("Pagina 3 en construccion")),
      
      tabItem("menu31",h1("Pagina 1 en construccion")),
      tabItem("menu32",h1("Pagina 2 en construccion")),
      tabItem("menu33",h1("Pagina 3 en construccion")),
      
      tabItem("menu41",h1("Pagina 1 en construccion")),
      tabItem("menu42",h1("Pagina 2 en construccion")),
      tabItem("menu43",h1("Pagina 3 en construccion")),
      
      tabItem("menu51",h1("Pagina 1 en construccion")),
      tabItem("menu52",h1("Pagina 2 en construccion")),
      tabItem("menu53",h1("Pagina 3 en construccion")),
      
      tabItem("menu61",h1("Pagina 1 en construccion")),
      tabItem("menu62",h1("Pagina 2 en construccion")),
      tabItem("menu63",h1("Pagina 3 en construccion"))
    )
  )
)

server <- function(input, output) {
  observe(print(input$sbmenu))
}
shinyApp(ui,server)
```


## Git

Git es un sistema de control de versiones. Permite llevar un registro de la historia de cambios de lo que uno quiera, todo tipo de archivos, no solo código. <https://git-scm.com/downloads>

comandos basicos:

- git clone: clonar un repositorio que ya existe.
- git status: estado del repositorio
- git add <nombre archivo>: agregar archivo para el seguimiento
- git commit -m "<mensaje>":  Hacer un commit, ponerle nombre al cambio que se hace.
- git push: subir lo cambios hechos
- git pull: bajar los cambios a local

Github es un servicio que permite llevar el control de versiones de un código fuente de forma colaborativa.

